[2021-09-14 15:58:06,623]:[cw2] [ERROR] EXCEPTION: ./slurm/DeepMindBallInCupDenseDMP-v0/log/rep_03
Traceback (most recent call last):
  File "/home/yre/anaconda3/envs/masterthesis/lib/python3.6/site-packages/cw2/job.py", line 84, in run_task
    self.exp.run(c, r, self.logger)
  File "/home/yre/anaconda3/envs/masterthesis/lib/python3.6/site-packages/cw2/experiment.py", line 79, in run
    res = self.iterate(cw_config, rep, n)
  File "cw2cmaes/cmaes_cw2.py", line 64, in iterate
    _, reward, __, ___ = self.env.step(solutions[i])
  File "/home/yre/Desktop/KIT/masterthesis/motion_primitive_env_api/mp_env_api/mp_wrappers/mp_wrapper.py", line 97, in step
    obs, rewards[t], done, info = self.env.step(actions[t, :])
  File "/home/yre/Desktop/KIT/masterthesis/Compare-Episodic-and-Step-based-Reinforcement-Learning/src/alr-envs/alr_envs/dmc/ball_in_cup/ball_in_the_cup_mp_wrapper_dense.py", line 54, in step
    a, reward, done, d = super().step(action)
  File "/home/yre/anaconda3/envs/masterthesis/lib/python3.6/site-packages/gym/core.py", line 268, in step
    observation, reward, done, info = self.env.step(action)
  File "/home/yre/anaconda3/envs/masterthesis/lib/python3.6/site-packages/gym/wrappers/time_limit.py", line 16, in step
    observation, reward, done, info = self.env.step(action)
  File "/home/yre/Desktop/KIT/masterthesis/Compare-Episodic-and-Step-based-Reinforcement-Learning/src/alr-envs/alr_envs/utils/dmc2gym_wrapper.py", line 160, in step
    time_step = self._env.step(action)
  File "/home/yre/anaconda3/envs/masterthesis/lib/python3.6/site-packages/dm_control/rl/control.py", line 113, in step
    self._task.after_step(self._physics)
  File "/home/yre/anaconda3/envs/masterthesis/lib/python3.6/site-packages/dm_control/suite/base.py", line 82, in after_step
    reward = np.clip(self.get_reward(physics), 0.0, 1.0)
  File "/home/yre/Desktop/KIT/masterthesis/Compare-Episodic-and-Step-based-Reinforcement-Learning/src/alr-envs/alr_envs/dmc/ball_in_cup/ball_in_the_cup_mp_wrapper_dense.py", line 85, in get_reward
    dist_final, dist = physics.ball_to_target()
  File "/home/yre/Desktop/KIT/masterthesis/Compare-Episodic-and-Step-based-Reinforcement-Learning/src/alr-envs/alr_envs/dmc/ball_in_cup/ball_in_the_cup_mp_wrapper_dense.py", line 101, in ball_to_target
    ball = self.env.physics.named.data.xpos['ball', ['x', 'z']]
  File "/home/yre/anaconda3/envs/masterthesis/lib/python3.6/site-packages/dm_control/mujoco/index.py", line 497, in __getitem__
    return self._field[self._convert_key(key)]
  File "/home/yre/anaconda3/envs/masterthesis/lib/python3.6/site-packages/dm_control/mujoco/index.py", line 479, in _convert_key
    for axis, key_item in zip(self._axes, key))
  File "/home/yre/anaconda3/envs/masterthesis/lib/python3.6/site-packages/dm_control/mujoco/index.py", line 479, in <genexpr>
    for axis, key_item in zip(self._axes, key))
  File "/home/yre/anaconda3/envs/masterthesis/lib/python3.6/site-packages/dm_control/mujoco/index.py", line 366, in convert_key_item
    key_item.shape = original_shape
KeyboardInterrupt
[2021-09-14 15:59:01,164]:[cw2] [ERROR] EXCEPTION: ./slurm/DeepMindBallInCupDenseDMP-v0/log/rep_03
Traceback (most recent call last):
  File "/home/yre/anaconda3/envs/masterthesis/lib/python3.6/site-packages/cw2/job.py", line 84, in run_task
    self.exp.run(c, r, self.logger)
  File "/home/yre/anaconda3/envs/masterthesis/lib/python3.6/site-packages/cw2/experiment.py", line 79, in run
    res = self.iterate(cw_config, rep, n)
  File "cw2cmaes/cmaes_cw2.py", line 64, in iterate
    _, reward, __, ___ = self.env.step(solutions[i])
  File "/home/yre/Desktop/KIT/masterthesis/motion_primitive_env_api/mp_env_api/mp_wrappers/mp_wrapper.py", line 97, in step
    obs, rewards[t], done, info = self.env.step(actions[t, :])
  File "/home/yre/Desktop/KIT/masterthesis/Compare-Episodic-and-Step-based-Reinforcement-Learning/src/alr-envs/alr_envs/dmc/ball_in_cup/ball_in_the_cup_mp_wrapper_dense.py", line 54, in step
    a, reward, done, d = super().step(action)
  File "/home/yre/anaconda3/envs/masterthesis/lib/python3.6/site-packages/gym/core.py", line 268, in step
    observation, reward, done, info = self.env.step(action)
  File "/home/yre/anaconda3/envs/masterthesis/lib/python3.6/site-packages/gym/wrappers/time_limit.py", line 16, in step
    observation, reward, done, info = self.env.step(action)
  File "/home/yre/Desktop/KIT/masterthesis/Compare-Episodic-and-Step-based-Reinforcement-Learning/src/alr-envs/alr_envs/utils/dmc2gym_wrapper.py", line 160, in step
    time_step = self._env.step(action)
  File "/home/yre/anaconda3/envs/masterthesis/lib/python3.6/site-packages/dm_control/rl/control.py", line 113, in step
    self._task.after_step(self._physics)
  File "/home/yre/anaconda3/envs/masterthesis/lib/python3.6/site-packages/dm_control/suite/base.py", line 83, in after_step
    _set_reward_colors(physics, reward)
  File "/home/yre/anaconda3/envs/masterthesis/lib/python3.6/site-packages/dm_control/suite/base.py", line 108, in _set_reward_colors
    colors[_MATERIALS] = blend_coef * highlight + (1.0 - blend_coef) * default
KeyboardInterrupt
