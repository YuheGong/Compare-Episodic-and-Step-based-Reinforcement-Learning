algo_params:
  batch_size: 50
  learning_rate: 0.0001
  n_steps: 2000
  num_timesteps: 1008000
  special_policy: MlpPolicy
  total_timesteps: 1000000.0
algorithm: ppo
env_params:
  env_name: alr_envs:HoleReacherDense-v0
  num_envs: 8
  wrapper: VecNormalize
name: HoleReacherDense + PPO
path: logs/ppo/HoleReacherDense-v0_2
