algo_params:
  batch_size: 50
  learning_rate: 0.0001
  n_steps: 2000
  num_timesteps: 1072000
  special_policy: MlpPolicy
  total_timesteps: 2000000.0
algorithm: ppo
env_params:
  env_name: alr_envs:DenseHoleReacher-v0
  num_envs: 8
  wrapper: VecNormalize
name: DenseHoleReacher + PPO
path: logs/ppo/DenseHoleReacher-v0_1
