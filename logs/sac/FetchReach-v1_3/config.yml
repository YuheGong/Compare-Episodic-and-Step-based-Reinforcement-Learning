algo_params:
  batch_size: 200
  learning_rate: 0.0001
  n_steps: 20000
  num_timesteps: 0
  policy: MlpPolicy
  policy_kwargs:
    activation_fn: tanh
    pi: 256
    qf: 256
  policy_type: off_policy
  total_timesteps: 2000000.0
  train_freq: 1
algorithm: sac
env_params:
  env_name: gym:FetchReach-v1
  num_envs: 1
  wrapper: None
eval_env:
  eval_freq: 1000
  n_eval_episode: 10
path: logs/sac/FetchReach-v1_3
path_in: logs/sac/FetchReach-v1_3/SAC_1
path_out: logs/sac/FetchReach-v1_3/data.csv
seed: null
